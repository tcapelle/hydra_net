{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e547be-06ae-48b1-822b-e20e64e04d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6732b-6f6c-47c9-b9b2-20e7bf50bebb",
   "metadata": {},
   "source": [
    "# A simple set of training classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba23de30-03d4-4fe0-a59f-e052b2cea848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from fastcore.all import *\n",
    "from tqdm.notebook import tqdm\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from hydranet.utils import *\n",
    "from hydranet.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08fef345-4c88-4ca4-9b0c-fae14118e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Trainer:\n",
    "    \"A simple trainer using Accelerate\"\n",
    "    def __init__(self, train_dl, model, loss_func, valid_dl=None, fp16=False, log=True):\n",
    "        store_attr()\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.acc = Accelerator(fp16=fp16)\n",
    "        if log:\n",
    "            wandb.init(project=\"HydraNet\", entity=\"hydranet\")\n",
    "    \n",
    "    def prepare(self):\n",
    "        self.model, self.optimizer, self.train_dl, self.valid_dl = self.acc.prepare(self.model, self.optimizer, self.train_dl, self.valid_dl)\n",
    "    \n",
    "    def one_batch(self, dl=\"train\"):\n",
    "        if dl == \"train\":\n",
    "            dl = self.train_dl \n",
    "        elif dl == \"valid\":\n",
    "            dl = self.valid_dl\n",
    "        return next(iter(dl))\n",
    "    \n",
    "    def train_step(self, inputs, targets):\n",
    "\n",
    "        # Forward pass ➡\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss_func(outputs, targets)\n",
    "\n",
    "        # Backward pass ⬅\n",
    "        self.optimizer.zero_grad()\n",
    "        self.acc.backward(loss)\n",
    "        \n",
    "        # Step with optimizer\n",
    "        self.optimizer.step()\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def train_log(self, loss, example_ct, pbar):\n",
    "        # Where the magic happens\n",
    "        if self.log:\n",
    "            wandb.log({\"train_loss\": loss}, step=example_ct)\n",
    "        pbar.set_postfix({\"Loss\" : f'{loss:.3f}'})\n",
    "    \n",
    "    def train_one_epoch(self):\n",
    "        for b in (pbar :=tqdm(self.train_dl, leave=False)):\n",
    "            images, depths, labels = b\n",
    "            loss = self.train_step(images, depths).item()\n",
    "            self.example_ct +=  len(images)\n",
    "            self.train_log(loss, self.example_ct, pbar)\n",
    "        return loss\n",
    "    \n",
    "    def valid_log(self, loss, example_ct):\n",
    "        # Where the magic happens\n",
    "        if self.log:\n",
    "            wandb.log({\"val_loss\": loss}, step=example_ct)\n",
    "    \n",
    "    def eval_one_epoch(self):\n",
    "        self.model.eval()\n",
    "        val_loss = 0.\n",
    "        with torch.inference_mode():\n",
    "            for i, b in tqdm(enumerate(self.valid_dl), leave=False):\n",
    "                inputs, targets, _ = b\n",
    "                # Forward pass ➡\n",
    "                preds = self.model(inputs)\n",
    "                # accum loss\n",
    "                val_loss += self.loss_func(preds, targets)*len(inputs)\n",
    "                if self.log and i==0:\n",
    "                    self.log_image_table(inputs, preds, targets)\n",
    "        val_loss = val_loss/len(self.valid_dl.dataset)\n",
    "        self.valid_log(val_loss, self.example_ct)\n",
    "        return val_loss\n",
    "        \n",
    "        \n",
    "    def _fit(self, epochs=5):\n",
    "        self.example_ct = 0\n",
    "        self.prepare()\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            loss = self.train_one_epoch()\n",
    "            val_loss = self.eval_one_epoch()\n",
    "            print(f\"i={epoch}, train_loss={loss:3f}, val_loss={val_loss:3f}\")\n",
    "        if self.log:\n",
    "            wandb.finish()\n",
    "        \n",
    "    @delegates(Adam, but=\"lr\")        \n",
    "    def fit(self, epochs=5, lr=1e-3, **kwargs):\n",
    "        self.model.train()\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=lr, **kwargs)\n",
    "        self._fit(epochs)\n",
    "            \n",
    "    @delegates(Adam, but=\"lr\")     \n",
    "    def fit_one_cyle(self, epochs=5, lr=1e-3, max_lr=1e-1, **kwargs):\n",
    "        self.model.train()\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=lr, **kwargs)\n",
    "        self.scheduler = OneCycleLR(self.optimizer, \n",
    "                                    max_lr=max_lr, \n",
    "                                    steps_per_epoch=len(self.train_dl), \n",
    "                                    epochs=epochs)\n",
    "        self._fit(epochs)\n",
    "        \n",
    "    def predict_one_batch(self, dl=\"valid\"):\n",
    "        self.model.eval()\n",
    "        with torch.inference_mode():\n",
    "            b = self.one_batch(dl=\"valid\")\n",
    "            inputs, targets, _ = b\n",
    "            preds = self.model(inputs)\n",
    "            \n",
    "        return inputs, preds, targets\n",
    "    \n",
    "    @staticmethod\n",
    "    def _show_preds(inputs, preds, targets, max_n=9):\n",
    "        for i, (img, pred, tar) in enumerate(zip(inputs[:max_n], preds[:max_n], targets[:max_n])):\n",
    "            show_images([img, pred, tar], titles=[\"img\", \"pred\", \"tar\"] if i==0 else None)\n",
    "            \n",
    "    def show_results(self, dl=\"valid\"):\n",
    "        res = self.predict_one_batch(dl=\"valid\")\n",
    "        self._show_preds(*res)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _wandb_table(inputs, preds, targets):\n",
    "        table = wandb.Table(columns=[\"image\", \"pred\", \"target\"])\n",
    "        for img, pred, targ in zip(inputs.to(\"cpu\"), preds.to(\"cpu\"), targets.to(\"cpu\")):\n",
    "            table.add_data(wandb.Image(img.permute(1,2,0).numpy()*255), \n",
    "                           wandb.Image(to_viridis(pred)), \n",
    "                           wandb.Image(to_viridis(targ)))\n",
    "            return table\n",
    "    \n",
    "    def log_image_table(self, inputs, preds, targets):\n",
    "        \"Log a wandb.Table with (img, pred, target)\"\n",
    "        table = self._wandb_table(inputs, preds, targets)\n",
    "        wandb.log({\"predictions_table\":table}, commit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d511f53-5672-4a38-95e0-ca6ae5e74474",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4971ecd5-b742-4ae9-ba65-f1c16310317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data.ipynb.\n",
      "Converted 02_layers.ipynb.\n",
      "Converted 03_models.ipynb.\n",
      "Converted 04_trainer.ipynb.\n",
      "Converted 10_baseline_train.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
