{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b9828-51dd-48b3-aa48-2d03e6efd947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ecacb-37ad-421d-bd4a-89a8ba60b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "from fastcore.all import *\n",
    "from fastdownload import FastDownload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8953fc4-b251-410b-8754-ac2828fd64f5",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9fee1-c114-42d4-b609-df14b6f1c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# This comes from fastai.torch_core\n",
    "\n",
    "def _fig_bounds(x):\n",
    "    r = x//32\n",
    "    return min(5, max(1,r))\n",
    "\n",
    "@delegates(plt.Axes.imshow, keep=True, but=['shape', 'imlim'])\n",
    "def show_image(im, ax=None, figsize=None, title=None, ctx=None, **kwargs):\n",
    "    \"Show a PIL or PyTorch image on `ax`.\"\n",
    "    # Handle pytorch axis order\n",
    "    if hasattrs(im, ('data','cpu','permute')):\n",
    "        im = im.data.cpu()\n",
    "        if im.shape[0]<5: im=im.permute(1,2,0)\n",
    "    elif not isinstance(im,np.ndarray): im=array(im)\n",
    "    # Handle 1-channel images\n",
    "    if im.shape[-1]==1: im=im[...,0]\n",
    "\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if figsize is None: figsize = (_fig_bounds(im.shape[0]), _fig_bounds(im.shape[1]))\n",
    "    if ax is None: _,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, **kwargs)\n",
    "    if title is not None: ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "@delegates(plt.subplots)\n",
    "def show_images(ims, nrows=1, ncols=None, titles=None, **kwargs):\n",
    "    \"Show all images `ims` as subplots with `rows` using `titles`.\"\n",
    "    if ncols is None: ncols = int(math.ceil(len(ims)/nrows))\n",
    "    if titles is None: titles = [None]*len(ims)\n",
    "    axs = plt.subplots(nrows, ncols, **kwargs)[1].flat\n",
    "    for im,t,ax in zip(ims, titles, axs): show_image(im, ax=ax, title=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf8c344-4d46-4589-83a1-b72466a54e15",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b331cd-614b-4344-9457-35105a7c6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class NYUDataset:\n",
    "    \n",
    "    _titles=[\"img\", \"depth\", \"label\"]\n",
    "    \n",
    "    def __init__(self, dataset_path='data/nyu_depth_v2_labeled.mat', tfms=None):\n",
    "        data = mat73.loadmat(dataset_path)\n",
    "        self.images = data[\"images\"]\n",
    "        self.depths = data[\"depths\"]\n",
    "        self.labels = data[\"labels\"]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        timg = T.ToTensor()(self.images[..., idx])\n",
    "        tdepth = torch.as_tensor(self.depths[..., idx])\n",
    "        tlabel = torch.as_tensor(self.labels[None, :, :, idx].astype(np.int64))\n",
    "        return (timg, tdepth, tlabel)\n",
    "        \n",
    "    def show_one(self, idx=0):\n",
    "        show_images(self.__getitem__(idx), titles=self._titles)\n",
    "    \n",
    "    def __len__(self): return self.images.shape[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
